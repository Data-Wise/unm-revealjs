---
title: "Template UNM reveal.js"
format: 
  unm-revealjs:
    slide-number: c/t
author:
  - name: Your Name
    orcid: 0000-0000-0000-0000
    email: alias@email.com
    affiliations: Your Institution
# date: last-modified
execute: 
  echo: true 
---

# Introduction {.section-slide}

## Overview

In mathematical statistics, well-structured experimental designs and robust
analytical methods are essential for drawing valid conclusions about treatment
effects. A fundamental design is the **Completely Randomized Design (CRD)**, where
each experimental unit is randomly assigned to one of several treatments without
incorporating any blocking factors.

### Key Analytic Tool:

-   Tests whether at least two of several treatment means differ significantly.
-   Provides a framework for linear modeling, least squares estimation, and
    hypothesis testing.

## Learning Objectives

1.  Understand the rationale and structure of the CRD.
2.  Carry out a randomization procedure and interpret why coding treatments matters.
3.  Formulate and apply the one-way ANOVA model (including assumptions).
4.  Explore estimability, least squares estimation, and the distribution of
    estimators.
5.  Use the ANOVA test to decide if treatments differ significantly.
6.  Calculate sample size and power for planning experiments.
7.  Demonstrate R-based procedures for randomization, modeling, and ANOVA.

# CRD Overview

## Definition and Rationale

A **Completely Randomized Design (CRD)**:

-   **Definition:** Each experimental unit is randomly assigned to a single
    treatment, with no blocking.
-   **Advantages:** Simplicity, straightforward randomization, easy analysis.
-   **When to Use:** When no major nuisance factors (e.g., time, location) need
    special control.

## Example Scenarios

1.  Comparing three battery types: alkaline, lithium, and nickel-cadmium. Randomly
    assign each battery to a type and measure voltage endurance, measured in hours.

2.  Example from Public Health: Testing three diets for weight loss, randomly
    assigning participants to each diet. The diets could be low-carb, low-fat, and
    Mediterranean. The outcome could be weight loss in pounds.

3.  Examle from Psychology: Testing three study techniques for memory retention,
    randomly assigning students to each technique. The study techniques could be
    reading, flashcards, and practice tests. The outcome could be the number of words
    recalled.

## Flowchart of CRD Steps

```{mermaid}
%%| echo: false
%%| fig-align: center
flowchart TB
    A[Define Objectives] --> B[Identify Treatments]
    B --> C[Determine Sample Size]
    C --> D[Randomly Assign Units]
    D --> E[Collect Data]
    E --> F[Perform ANOVA & Interpret]
```

## R Implementation: Randomization Examples in CRD {.slide-code}

```{r}

N <- 12 # Number of experimental units, Step 1
# Define experimental units and treatments
experimental_units <- 1:N ## 10 experimental units
treatments <- c("A", "B", "C") ## 3 treatments, Step 2

# Repeat treatments to match the number of units. The code covers both balanced and unbalanced designs.
treatments <- rep(treatments, length.out = N)  ## Step 3

# For a balanced design, we can also use:
# treatments <- rep(treatments, each = N/length(treatments))

# Shuffle (randomize) treatments randomly to assign to units, Step 4
set.seed(123) ## For reproducibility
randomized_treatments <- sample(treatments)

# Create a data frame with randomized assignments
randomization_crd <- data.frame(Unit = experimental_units, Treatment = randomized_treatments)  ## Step 5
print(randomization_crd)
```


## Model Formulation

Consider $v$ treatments, each with $n$ observations:

$$
Y_{ij} = \mu + \tau_i + \varepsilon_{ij},
$$

-   $Y_{ij}$: Response from the $j$-th unit of treatment $i$.
-   $\mu$: Overall mean.
-   $\tau_i$: Effect of treatment $i$.
-   $\varepsilon_{ij}$: Random errors, assumed $\text{i.i.d. } N(0, \sigma^2)$.

**Null Hypothesis**: $H_0: \tau_1 = \tau_2 = \dots = \tau_v = 0$

## Example

If testing 4 different drug dosages (A, B, C, D) on patients' blood pressure
reduction:

-   $i$ in $\{A,B,C,D\}$
-   $\tau_i$ is each dosage's deviation from the overall mean
-   $\varepsilon_{ij}$ is random variation in patient responses

## Estimability and Least Squares Estimation-normal

- Not all model parameters ($\tau_i$) are independently estimable. 
- However, **estimable functions**, linear combinations of parameters that correspond to expected values of observed data, can be estimated uniquely.


The least squares estimators (LSEs) solve the normal equations obtained by
minimizing the sum of squared errors (SSE):

$$
\text{SSE} = \sum_{i=1}^v \sum_{j=1}^n (Y_{ij} - \hat{\mu}_i)^2,
$$ {#eq-sse}

where $\hat{\mu}_i$ is the estimated mean for treatment $i$. The LSE for each
treatment mean $\mu_i = \mu + \tau_i$ is simply the sample mean
$\bar{Y}_i = \frac{1}{n}\sum_{j=1}^n Y_{ij}$.


## Estimability and Least Squares Estimation-small{.small-slide}

- Not all model parameters ($\tau_i$) are independently estimable. 
- However, **estimable functions**, linear combinations of parameters that correspond to expected values of observed data, can be estimated uniquely.


The least squares estimators (LSEs) solve the normal equations obtained by
minimizing the sum of squared errors (SSE):

$$
\text{SSE} = \sum_{i=1}^v \sum_{j=1}^n (Y_{ij} - \hat{\mu}_i)^2,
$$ {#eq-sse}

where $\hat{\mu}_i$ is the estimated mean for treatment $i$. The LSE for each
treatment mean $\mu_i = \mu + \tau_i$ is simply the sample mean
$\bar{Y}_i = \frac{1}{n}\sum_{j=1}^n Y_{ij}$.

## Estimability and Least Squares Estimation-tiny {.tiny-slide}

- Not all model parameters ($\tau_i$) are independently estimable. 
- However, **estimable functions**, linear combinations of parameters that correspond to expected values of observed data, can be estimated uniquely.


The least squares estimators (LSEs) solve the normal equations obtained by
minimizing the sum of squared errors (SSE):

$$
\text{SSE} = \sum_{i=1}^v \sum_{j=1}^n (Y_{ij} - \hat{\mu}_i)^2,
$$ {#eq-sse}

where $\hat{\mu}_i$ is the estimated mean for treatment $i$. The LSE for each
treatment mean $\mu_i = \mu + \tau_i$ is simply the sample mean
$\bar{Y}_i = \frac{1}{n}\sum_{j=1}^n Y_{ij}$.

## ANOVA Table

| Source    | DF      | SS               | MS              | F-ratio |
| --------- | ------- | ---------------- | --------------- | ------- |
| Treatment | $v-1$   | $SS_{Treatment}$ | MST=SST/$v-1$   | MST/MSE |
| Error     | $N - v$ | $SSE_{Error}$   | MSE=SSE/$N - v$ |         |
| Total     | $N - 1$ | $SS_{Total}$     |                 |         |


## R Code for Power

```{r}
#| label: r-power
pwr::pwr.anova.test(k = 3, f = 0.3, sig.level = 0.05, power = 0.8)
```

Adjust parameters for effect size, alpha, and power.

## Additional Resources

1.  Dean, A., Voss, D., & DraguljiÄ‡, D. (2017). *Design and Analysis of Experiments*.
    Springer.\
2.  Montgomery, D. C., & Runger, G. C. (2010). *Applied Statistics and Probability
    for Engineers*. Wiley.\
3.  Christensen, R. (2018). *Analysis of Variance, Design, and Regression*. Chapman
    and Hall/CRC.\
4.  Libre Textbook: [Analysis of Variance and Design of Experiments]

  [Analysis of Variance and Design of Experiments]: https://stats.libretexts.org/Bookshelves/Advanced_Statistics/Analysis_of_Variance_and_Design_of_Experiments